[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Why the Name?\nNaming things really is as hard as cache invalidation. I spent a long time casting about for something to call the site before hitting on Verso. It means the reverse side of a physical document, such as the left-hand page of a book. The word attracted me because I aim to make this blog like a good anthology: you can visit any page and find something short but worth reading. As a publishing term derived from Italian, it has a pleasingly archaic resonance similar to “quarto”, the namesake of the file format this site’s documents are written in. Most important, it’s got an R.\nVerso was built with Quarto and deployed using Github Pages with a GitHub workflow developed by pommevilla. A previous version of this site was built with rendered Rmarkdown and the blogdown R package."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Verso",
    "section": "",
    "text": "Advent of Code\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nAug 14, 2022\n\n\nRyan Heslin\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJul 5, 2022\n\n\nRyan Heslin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\nPython\n\n\nAdvent of Code\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2022\n\n\nRyan Heslin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 25, 2022\n\n\nRyan Heslin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 18, 2022\n\n\nRyan Heslin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2022\n\n\nRyan Heslin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2022\n\n\nRyan Heslin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/ghost-machine/index.html",
    "href": "posts/ghost-machine/index.html",
    "title": "Ghost in the Machine: The Remnant of R’s Past That Haunts it Still",
    "section": "",
    "text": "But as many users know, its roots go back further. R was developed from the language S, created in the 1970s by a team led by John Chambers at Bell Labs. Those were the glory days of Bell Labs, when the language C and the Unix ecosystem were developed. Like a modern palace built on the foundations of an ancient one, R bears many traces of its lineage. Syntax is very similar, many features are backward-compatible, and the documentation for some functions even refers to resources about S rather than R. (Try ?sum, for one example).\n(I can’t help but pause here to relay the account the linked presentation gives of R’s origins. It all began with this hallway conversation between Ross Ihaka and Robert Gentleman in the University of Auckland around 1990):\n\nGentleman: “Let’s write some software.”\nIhaka: “Sure, that sounds like fun.”\n\nOne of those traces, harder to observe but certainly still present, is also one of R’s most unusual (and, in some quarters, derided) features: an emphasis on convenience in interactive use. Interpreted languages typically support interactivity in some way, since the ability to run a snippet of code and instantly get results is one of their greatest advantages over compiled languages. But S was designed primarily for interactive data exploration, and R has retained that capability as a design focus. In areas great and small, from core design choices to implementation quirks, R makes it as easy as possible to bang out code in the console and see what happens. That makes it a fast, flexible tool for exploring data and following hunches. It also strews mines in the path of anyone programming in the language without detailed knowledge of the its nuances.\nA few examples will make this painfully clear.\nPartial Matching, Complete Headache\nCan you spot the problem with this call? It runs correctly:\n\nrep(1:3, length = 10)\n\n--  [1] 1 2 3 1 2 3 1 2 3 1\n\n\nbut is missing something. The relevant argument of rep is actually called length.out, not length, but R’s partial argument matching saves us, since length is a shortened form of length.out.\nThis is nice to have when typing code in the console. But relying on partial argument matching in scripts is a very bad idea.\nSuppose you’re working with a package that includes some functions with annoyingly long argument names. All that typing is annoying, so you decide you may as well save some keystrokes:\n\nfoo <- function(xyzabc = 0, abcxyz) {\n  rnorm(100, mean = xyzabc, sd = abcxyz)\n}\nfoo(abc = 2)\n\n--   [1] -2.2445375393  0.0006980033  2.7545888572\n--   [4]  2.4408344499  1.0603102701  1.0339639753\n--   [7] -2.5538325776 -2.3821797163  1.4241402187\n--  [10]  3.4608888276 -1.7982607952 -2.6028331590\n--  [13] -1.9567956312  3.0330076639  1.6970384912\n--  [16] -1.6846503588  0.7703500154  2.0788886200\n--  [19] -1.4633401345 -0.5573480895 -2.0095198162\n--  [22] -1.6895435431  3.1311811856  3.1310047213\n--  [25]  1.4729583077 -1.0263057542 -1.5847273796\n--  [28] -0.4799545029 -1.7888803568 -1.9245995464\n--  [31] -4.6330110103 -1.9715598153  1.4599438684\n--  [34]  2.7132587288  0.6528931467  2.5852043149\n--  [37]  1.0905654293  0.2725256704  1.6970369709\n--  [40] -2.0199561628  2.5247942430 -0.7553546067\n--  [43] -2.1349384104  2.9145587148 -0.7345825950\n--  [46] -5.1058990327  4.9231247499 -0.6035536464\n--  [49] -2.3265457843  0.3302235222 -1.3918293057\n--  [52]  1.0125287082  1.0594286242  0.3381375636\n--  [55] -2.6480325601  2.6698135931  0.6011187892\n--  [58]  0.8268423770  2.0615727017  0.7820518214\n--  [61]  0.8661731658  1.6124350173 -3.4892935968\n--  [64]  1.1309708077 -2.6950092921  1.3708731989\n--  [67]  0.8005728911  1.9657901299 -0.0740493745\n--  [70] -1.9168890455 -0.4764915602  1.0063471749\n--  [73] -1.0145137420 -2.9367465377  1.8716120776\n--  [76]  2.5652162753 -4.1357088596  0.1449861917\n--  [79] -0.1510655209  0.8926796265  2.0724077350\n--  [82]  0.8070621653 -2.2783598309 -2.1981171179\n--  [85]  0.2787279686 -0.6897820741  0.2305332864\n--  [88]  3.7423003005 -0.5410520289 -0.0798217270\n--  [91]  2.2024273761  2.0151796646  0.1497940941\n--  [94]  1.7381047108  4.8335993704 -1.0045015749\n--  [97]  0.4051954986 -0.7421079463  1.3928131504\n-- [100] -0.3842254215\n\n\nAll seems well. But then a version update adds a new argument:\n\nfoo <- function(abcabc = 100, xyzabc = 0, abcxyz) {\n  rnorm(abcabc, mean = xyzabc, sd = abcxyz)\n}\nfoo(abc = 2)\n\n-- Error in foo(abc = 2): argument 1 matches multiple formal arguments\n\n\nR throws an error, unable to find an unambiguous match. (Imagine how painful this would be to debug if R defaulted to the first match instead). The way to avoid this scenario is simple: never rely on partial argument matching in permanent code. Nonetheless, many packages do. You can identify offenders yourself by setting the warnPartialMatchArgs option:\n\noptions(warnPartialMatchArgs = TRUE)\nfoo <- function(xyzabc = 0, abcxyz) {\n  rnorm(100, mean = xyzabc, sd = abcxyz)\n}\nfoo(abc = 2)\n\n-- Warning in foo(abc = 2): partial argument match of\n-- 'abc' to 'abcxyz'\n\n\n--   [1]  1.135737632  0.898777992 -1.168305721\n--   [4] -0.200356691  1.896926857 -2.195331088\n--   [7] -2.358100545 -0.964742402 -0.434256333\n--  [10] -0.866615153 -1.695076565 -1.216676274\n--  [13] -0.701648479  0.116874260  1.539296099\n--  [16] -1.855742680  0.668820756  0.956655247\n--  [19] -0.877439502 -0.587614465 -2.665958758\n--  [22]  1.773477792 -2.863720703  3.763074651\n--  [25]  0.465025688 -0.769830396 -2.432551929\n--  [28] -1.014383156 -2.612857969  2.458936219\n--  [31]  4.574751630  1.904787119 -1.296354990\n--  [34] -1.255039919 -2.211310672  2.345390787\n--  [37] -4.428351645  1.320426681  3.489979652\n--  [40]  0.096533032  0.458937039 -0.102943023\n--  [43] -1.250962819 -1.985484776 -1.218318017\n--  [46]  1.326497455 -1.508000185  0.677995117\n--  [49] -1.311472616  0.827359346 -0.021029545\n--  [52] -1.573747438 -0.468632693  2.537835106\n--  [55] -0.322118384 -1.811239945 -2.142289035\n--  [58] -1.474554406  0.167728454 -0.747559158\n--  [61]  1.643024687  5.315610537 -0.454848607\n--  [64]  0.334280121  0.407075141  2.832402127\n--  [67]  4.496262431  4.541043228  1.615224374\n--  [70] -0.809748220  0.172601480 -0.818599327\n--  [73] -2.450540595  1.267560384  1.585044337\n--  [76]  4.241263923 -3.659138113  2.707283449\n--  [79] -0.005228332  3.708947137  2.734984132\n--  [82]  3.740473434 -2.344453443 -1.725388978\n--  [85]  2.835911189  1.903218359 -2.937334230\n--  [88]  1.012619409 -1.685953117  0.284221601\n--  [91]  1.660654555  4.480118551  0.001522222\n--  [94] -3.086320143 -2.858898255  2.692280552\n--  [97] -1.012438393  0.107822384 -1.982872158\n-- [100]  2.153669313\n\n\nWhen Simplification Complicates\nR is an example of a weakly typed language with dynamic typing. That means data types are known only at runtime, not before, and that the language will try to coerce disparate types to a common type instead of throwing an error. That means the interpreter will happily run code like\n\npaste(mtcars, 1)\n\n--  [1] \"c(21, 21, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8, 16.4, 17.3, 15.2, 10.4, 10.4, 14.7, 32.4, 30.4, 33.9, 21.5, 15.5, 15.2, 13.3, 19.2, 27.3, 26, 30.4, 15.8, 19.7, 15, 21.4) 1\"                    \n--  [2] \"c(6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8, 8, 8, 8, 4, 4, 4, 8, 6, 8, 4) 1\"                                                                                                            \n--  [3] \"c(160, 160, 108, 258, 360, 225, 360, 146.7, 140.8, 167.6, 167.6, 275.8, 275.8, 275.8, 472, 460, 440, 78.7, 75.7, 71.1, 120.1, 318, 304, 350, 400, 79, 120.3, 95.1, 351, 145, 301, 121) 1\"                       \n--  [4] \"c(110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180, 205, 215, 230, 66, 52, 65, 97, 150, 150, 245, 175, 66, 91, 113, 264, 175, 335, 109) 1\"                                                     \n--  [5] \"c(3.9, 3.9, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92, 3.07, 3.07, 3.07, 2.93, 3, 3.23, 4.08, 4.93, 4.22, 3.7, 2.76, 3.15, 3.73, 3.08, 4.08, 4.43, 3.77, 4.22, 3.62, 3.54, 4.11) 1\"                  \n--  [6] \"c(2.62, 2.875, 2.32, 3.215, 3.44, 3.46, 3.57, 3.19, 3.15, 3.44, 3.44, 4.07, 3.73, 3.78, 5.25, 5.424, 5.345, 2.2, 1.615, 1.835, 2.465, 3.52, 3.435, 3.84, 3.845, 1.935, 2.14, 1.513, 3.17, 2.77, 3.57, 2.78) 1\"  \n--  [7] \"c(16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20, 22.9, 18.3, 18.9, 17.4, 17.6, 18, 17.98, 17.82, 17.42, 19.47, 18.52, 19.9, 20.01, 16.87, 17.3, 15.41, 17.05, 18.9, 16.7, 16.9, 14.5, 15.5, 14.6, 18.6) 1\"\n--  [8] \"c(0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1) 1\"                                                                                                            \n--  [9] \"c(1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1) 1\"                                                                                                            \n-- [10] \"c(4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 4, 5, 5, 5, 5, 5, 4) 1\"                                                                                                            \n-- [11] \"c(4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2, 2, 4, 2, 1, 2, 2, 4, 6, 8, 2) 1\"\n\n\npaste just coerces everything to character, no matter how ludicrous the results. This behavior can trip you up, but it’s not truly insidious.\nUnfortunately, R sometimes changes types under your nose. Suppose we write a function, subset2. It takes as argument a data frame, and two functions that take a data frame as argument. It filters the data column-wise using col_f, then rowwise using row_f.\n\nsubset2 <- function(df, col_f, row_f) {\n  df <- df[, col_f(df)]\n  df[row_f(df), ]\n}\nsubset2(mtcars, \\(x) colSums(x) > 500, \\(x) rowSums(x) > 500)\n\n\n\n  \n\n\n\nThat seems to work. (Deadly words!) But what if my finger had slipped when I typed 500?\n\nsubset2 <- function(df, col_f, row_f) {\n  df <- df[row_f, col_f(df)]\n  df[row_f(df), ]\n}\nsubset2(mtcars, \\(x) colSums(x) > 5000, \\(x) rowSums(x) > 500)\n\n-- Error in xj[i]: invalid subscript type 'closure'\n\n\nWhat happened? Only one column of mtcars, disp, has a column sum greater than 5000. And what happens if you select a single column with array-style indexing?\n\nmtcars[, \"disp\"]\n\n--  [1] 160.0 160.0 108.0 258.0 360.0 225.0 360.0\n--  [8] 146.7 140.8 167.6 167.6 275.8 275.8 275.8\n-- [15] 472.0 460.0 440.0  78.7  75.7  71.1 120.1\n-- [22] 318.0 304.0 350.0 400.0  79.0 120.3  95.1\n-- [29] 351.0 145.0 301.0 121.0\n\n\nR helpfully simplifies to an atomic vector. We can fix our function by disabling this behavior:\n\nsubset3 <- function(df, col_f, row_f) {\n  df <- df[, col_f(df), drop = FALSE]\n  df[row_f(df), ]\n}\nsubset3(mtcars, \\(x) colSums(x) > 5000, \\(x) rowSums(x) > 500)\n\n-- numeric(0)\n\n\nor, even more sensibly, using list subsetting (single brackets, no comma), which never simplifies.\nThis behavior isn’t indefensible. It’s consistent with how subsetting works on arrays (which are usually atomic vectors). In interactive use, it’s convenient, since then you’re usually interested in the data a column contains, not the object containing it. But automatic simplification is easily missed and potentially destructive, and the way to avoid it can be found only if you carefully read the documentation.\nBrevity is the Soul of Bugs\nSuppose you have the following vector:\n\nx <- c(1, 4, 7, NA, -9, NA)\n\nR is strict about missing values, but not about logical constants. T and F can be used as abbreviations for TRUE and FALSE, respectively. The following is a valid way of taking the mean:\n\nmean(x, na.rm = T)\n\n-- [1] 0.75\n\n\nLikewise, with F for FALSE:\n\nmtcars[1:5, \"cyl\", drop = F]\n\n\n\n  \n\n\n\nWhat’s the harm in this? While TRUE and FALSE are reserved words, the abbreviations aren’t. Let’s say your colleague creates a variable T, making sure to use uppercase to avoid masking the t function:\n\nT <- pt(2, df = 10)\n\nThis code now fails in a confusing way:\n\nmean(x, na.rm = T)\n\n-- [1] NA\n\n\nThe reason for this feature, as before, is clear: it’s convenient in interactive use. The problem with it is equally clear: it’s suicidal in programmatic use.\nConclusion\nThe theme here is obvious: features that save a few keystrokes in interactive use can cause maddening bugs if carelessly used in production code. You need familiarity with the language and some degree of vigilance to avoid the pitfalls, and everyone slips now and again.\nThe longer I’ve spent with R, the more convinced I’ve become that R has outgrown these features. R was designed as an environment for interactive data exploration, statistical testing, and graphical displays, but today it can do so much more: serve Web apps, query remote databases, render just about any document (even this one) with Rmarkdown or Quarto, and many other uses. But to fulfill these sophisticated use cases, you have to carefully avoid traps like the ones discussed here. Some organizations have no doubt avoided the problem by switching to Python. So R’s design emphasis on interactivity may limit its growth.\nMoreover, the benefits these features deliver are scant. The three behaviors I describe - partial argument matching, logical abbreviations, and drop = FALSE save a bit of typing (or, in the last case, an extra step of data manipulation). A few key strokes saved here and there adds up quickly, and the savings may have been significant in the days when users were limited to R’s basic readline prompt. But that doesn’t balance the potential harm they can cause in production code today, especially when modern IDEs (and Vim or Emacs, of course) support autocompletion, obviating the need for abbreviated code.\nDon’t get me wrong. R remains a powerful, expressive language built on solid design principles. It’s my first choice for any kind of data manipulation, and I still find it fun and satisfying to use. But some of its behaviors are more at home in its past than its future."
  },
  {
    "objectID": "posts/lesser-known/index.html",
    "href": "posts/lesser-known/index.html",
    "title": "R Tricks I Wish I’d Known as a Beginner",
    "section": "",
    "text": "R is full of quirks, some of them obscure. Getting the most out of the language takes some experience, but is well worth the effort. These techniques will be old hat to seasoned R users, but you never know: you might still learn something."
  },
  {
    "objectID": "posts/lesser-known/index.html#get-the-expressions-passed-as-function-arguments",
    "href": "posts/lesser-known/index.html#get-the-expressions-passed-as-function-arguments",
    "title": "R Tricks I Wish I’d Known as a Beginner",
    "section": "Get the Expressions Passed as Function Arguments",
    "text": "Get the Expressions Passed as Function Arguments\nR passes function arguments by value, not by reference, yet it’s possible to recover the symbol or expression passed to a function using this trick:\n\nf <- function(x) {\n  x <- deparse(substitute(x))\n  print(x)\n}\nf(`I'm a symbol!`)\n\n-- [1] \"I'm a symbol!\"\n\n\nsubstitute, when called in a function, replaces its argument with the expression in the promise corresponding to that argument. (Promises are internal objects that implement function arguments). deparse converts that unevaluated R code into a character vector.\nThis could be used to make a function that automatically labels plot axes:\n\ndescriptive_plot <- function(x, y) {\n  x_name <- deparse(substitute(x))\n  y_name <- deparse(substitute(y))\n  plot(x, y, xlab = x_name, ylab = y_name)\n}\nweight <- mtcars$wt\nmpg <- mtcars$mpg\ndescriptive_plot(mpg, weight)\n\n\n\n\n\n\n\nWhat are your favorite R tricks?"
  },
  {
    "objectID": "posts/R6-active/index.html",
    "href": "posts/R6-active/index.html",
    "title": "Programatically Creating Accessor Functions for R6 Objects",
    "section": "",
    "text": "library(R6)\n\nunprotected <- R6Class(\n  classname = \"unprotected\",\n  public = list(foo = 1, bar = 2, baz = 3)\n)\nexample <- unprotected$new()\nexample$foo\n\n-- [1] 1\n\nexample$foo <- 2\nexample$foo\n\n-- [1] 2\n\n\nFields can be protected by sending them to private instead, but that blocks the user from accessing them. The solution is to create an active field. This creates an active binding: a special form of R function that can be used to return a value if called with no arguments and to bind a value if called with one. We can use this capability to create an accessor function that blocks users from changing values:\n\nprotected <- R6Class(\n  classname = \"example\",\n  public = list(\n    bar = 2, baz = 3,\n    initialize = function(foo) private$.foo <- foo\n  ),\n  private = list(.foo = NULL),\n  active = list(foo = function(value) {\n    if (missing(value)) {\n      return(private$.foo)\n    } else {\n      stop(\"Hands off!\")\n    }\n  })\n)\n\nexample <- protected$new(foo = 1)\nexample$foo\n\n-- [1] 1\n\nexample$foo <- 2\n\n-- Error in (function (value) : Hands off!\n\n\n(See chapter 14 of Advanced R for more details).\nThis is all simple enough, but there’s an obvious problem: what if we have a lot of attributes to protect? We could dodge the problem by combining them into a single list attribute, or just copy-paste the same function with different attribute names. But those options aren’t always attractive. I recently confronted this problem while working on an elaborate subclass of torch::dataset, which organizes data for neural networks. I decided to rifle through my bag of functional programming tricks in search of a solution.\nFirst Attempt: Function Factory\nSince each active field requires a function, a function factory was an obvious approach. It’s simple to implement:\n\naccessor_factory <- function(field) {\n  force(field)\n  function(value) {\n    if (missing(value)) {\n      return(private[[\"field\"]])\n    } else {\n      stop(\"Hands off \", field, \"!\")\n    }\n  }\n}\n\n(The real version used a less jocular error message, but I need to have my fun somehow). Because R has lexical scope, field is bound in the manufactured function’s enclosing environment, so when executed it should look there and find it.\nBut it doesn’t work.\n\nprotected <- R6Class(\n  classname = \"example\",\n  public = list(\n    bar = 2, baz = 3,\n    initialize = function(foo) private$.foo <- foo\n  ),\n  private = list(.foo = NULL),\n  active = list(foo = accessor_factory(\".foo\"))\n)\nexample <- protected$new(1)\nexample$foo\n\n-- NULL\n\nexample$foo <- 2\n\n-- Error in lapply(list(...), as.character): object 'field' not found\n\n\nEither R core sneaked support for dynamic scope into the last major version, or the R6Class constructor was doing something funny. Checking the source code found the offending line:\n\ngenerator_funs <- assign_func_envs(generator_funs, generator)\n\nThe constructor modified the environments of function fields (a trick I also resorted to while writing a different subclass, but that’s another story). Relying on scope wouldn’t help, but what would?\nSecond Attempt: as.function\n\nMy next idea was to use R’s obscure but powerful function constructor, as.function. It has a strange implementation: it takes a list, interpreting all elements except the last as name-value pairs for arguments (with an empty value slot designating an argument with no default). The last element should be an expression defining the function body. This is what I wrote:\n\naccessor_factory <- function(field) {\n  force(field)\n  code <- substitute(\n    {\n      if (missing(value)) {\n        return(private[[field]])\n      } else {\n        stop(sQuote(field), \" is read-only\")\n      }\n    },\n    list(field = field)\n  )\n  as.function(eval(substitute(\n    alist(value = , code),\n    list(code = code)\n  )),\n  envir = globalenv()\n  )\n}\n\nThis code demands some explanation. The idea is to return a function with the value of field already substituted, not set at runtime. The first step uses substitute to replace the symbol field with the value passed to the function (i.e., the name of the target attribute). The result forms the body of the manufactured function. I have to call substitute again to substitute this expression into the call to alist passed to as.function, because alist quotes its arguments. That expression actually creates the function we need. (See why most people consider me weird for liking metaprogramming?).\n\nprotected <- R6Class(\n  classname = \"example\",\n  public = list(\n    bar = 2, baz = 3,\n    initialize = function(foo) private$.foo <- foo\n  ),\n  private = list(.foo = NULL),\n  active = list(foo = accessor_factory(\".foo\"))\n)\nexample <- protected$new(1)\nexample$foo\n\n-- [1] 1\n\nexample$foo <- 2\n\n-- Error in (function (value) : '.foo' is read-only\n\n\nThis works. But can we do better?\nThird Attempt: Body Substitution\nR features assignment functions to modify all three parts of a closure: formal arguments, body, and environment. We’re interested in creating a set of functions with slightly different bodies, so pairing body<- with substitute is a natural approach. It’s a lot more readable than my last attempt, too. The classic double-substitute trick for substituting the result of an expression comes from Advanced R.\n\nsubstitute_body <- function(fn, mapping) {\n  body(fn) <- eval(substitute(substitute(temp, mapping), list(temp = body(fn))))\n  fn\n}\n\ntemplate <- function(value) {\n  if (missing(value)) {\n    return(private[[field]])\n  } else {\n    stop(sQuote(field), \" is read-only\")\n  }\n}\nsubstitute_body(template, mapping = list(field = \"test\"))\n\n-- function (value) \n-- {\n--     if (missing(value)) {\n--         return(private[[\"test\"]])\n--     }\n--     else {\n--         stop(sQuote(\"test\"), \" is read-only\")\n--     }\n-- }\n\n\nVictory! Well, almost. To make this truly useful, we need a wrapper function to create a list of accessors from field names. Thankfully, that’s much easier than figuring out the substitution.\n\nset_active_fields <- function(fields) {\n  out <- lapply(fields, function(x) {\n    substitute_body(\n      fn = template,\n      mapping = list(field = x)\n    )\n  })\n  names(out) <- gsub(\"^\\\\.\", \"\", fields)\n  out\n}\n\nA bog-standard use of lapply does the job, with the annoying complication of removing leading dots from the names of private fields.\nWe can even go one step further and write a wrapper to R6Class to automatically create accessors from a list of private attributes.\n\nwith_accessors <- function(classname = NULL,\n                           public,\n                           private,\n                           inherit = NULL, lock_objects = TRUE,\n                           class = TRUE,\n                           portable = TRUE, lock_class = FALSE,\n                           cloneable = TRUE,\n                           parent_env = (function() parent.frame())()) {\n  force(parent_env)\n  active <- set_active_fields(names(private))\n  R6Class(\n    classname = classname, public = public,\n    private = NULL, active = active,\n    inherit = inherit, lock_objects = lock_objects,\n    class = class,\n    portable = portable,\n    lock_class = lock_class,\n    cloneable = cloneable,\n    parent_env = parent_env\n  )\n}\n\n\npublic <- list(initialize = function(foo) {\n  private$.foo <<- foo\n})\nprivate <- list(.foo = NULL, .bar = 2, .baz = 3)\nprotected <- with_accessors(\"example\", public = public, private = private)\n\nexample <- protected$new(foo = 1)\nexample$foo\n\n-- [1] 1\n\nexample$bar\n\n-- [1] 2\n\nexample$baz\n\n-- [1] 3\n\nexample$foo <- 2\n\n-- Error in (function (value) : '.foo' is read-only\n\nexample$baz <- 5\n\n-- Error in (function (value) : '.baz' is read-only\n\n\nNote that because of the indirection, I have to use <<- in initialize. I also have to make parent_env the execution environment of the wrapper, which is the caller environment of R6Class here. There may also be other nasty surprises buried in this use of reference semantics. Still, this was a fun diversion, and proof of how much power R grants the user over environments and evaluation."
  },
  {
    "objectID": "posts/that_kind_of_a_day/index.html",
    "href": "posts/that_kind_of_a_day/index.html",
    "title": "That Kind of a Day",
    "section": "",
    "text": "In fairness, is.numeric ought to be called is_numeric, because dots are supposed to be reserved for S3 methods. R breaks this rule all the time, leading to names like as.data.frame.data.frame. R updates are named after Peanuts strips; getting dinged by the linter for using a base function is something that would happen to Charlie Brown if he ever took up programming. Apparently, whatever method lintr uses to exempt base function names from linting doesn’t work when those function names are arguments to another function.\nAs you might guess from the traceback thirty calls deep on the right of the screen, this wasn’t a great day. But I can’t help but smile when I see a linter commit heresy."
  },
  {
    "objectID": "posts/triumph-travesty/index.html",
    "href": "posts/triumph-travesty/index.html",
    "title": "Triumph and Travesty: Earning All 50 Stars in Advent of Code 2021",
    "section": "",
    "text": "If you haven’t heard of Advent of Code, it’s well worth your time to check out. Created and maintained by software engineer Eric Wastl, Advent of Code (AoC for short) is an annual event involving an advent calendar of Christmas-themed programming challenges. Anyone can participate for free, anonymously if they like. A new puzzle is released on each of the first 25 days of December. They start simple and gradually increase in difficulty. Elite players compete for spots on the official leaderboard of the fastest solutions, but most (myself included) just aim to solve the puzzles. Each puzzle(with one exception) awards two “gold stars” when completed, providing a way to track your progress.\nThe puzzles themselves take the form of well-posed problems, connected through a whimsical yuletide narrative. This year’s edition sent players to the ocean depths in a submarine to retrieve the lost keys to Santa’s sleigh. Along the way, they encountered treacherous currents, labyrinthine caves, and a whole lot of obstreperous sea creatures - all of which could only be overcome with some creative programming (Half the fun is recognizing the classical computer science problems underneath the intentonally silly presentation). Each puzzle consists of two parts. The first part states the problem, with any necessary rules, and offers a plaintext input (randomly generated for each player) to work from. If the player submits the correct answer, they receive a gold star…and updated instructions with a new version of the problem to solve. It usually adds a new constraint or asks the player to interpret the input in a different way; depending on the problem and the player’s approach for part 1, overcoming it could take anything from changing a single line to starting from scratch. Submitting the correct answer for the second part earns another gold star and completes that day’s puzzle. (The lone exception to the standard format is the Christmas Day puzzle, which differs in a way I won’t spoil). Players can use whatever language and strategy they like; some solve puzzles in absurd (or do I mean awesome) languages like Rockstar, or impose tough constraints, because they can.\nThe puzzles test a wide variety of programming techniques, from recursion to graph traversal to regular expressions. The problem statements are all “fair” - there are no hidden rules or lawyerly gotchas - but even a subtle misunderstanding can cost you hours of frustrating debugging (just like real life!). With no constraints and no expectation to write production-quality code, you’re free to tackle each problem as you see fit, limited only by your knowledge and creativity.\nI stumbled across AoC in late 2020, a pivotal time in my life. Perhaps a month before, realizing I liked programming a lot more than policy analysis, I had decided to convert my masters degree from public policy to data science. With enough experience in R to feel (over)confident in my programming skills, I dove in without hesitation and spent much of that holiday break absorbed in the puzzles. Tackling such beautifully abstract problems, with no pressure and no shame in failing, was bliss; I enjoyed even the frustration. Realizing R was ill-suited for many of the puzzles, I switched to Python, learning it as I went. I only ever solved some of the puzzles, and those in amateurish fashion (look here if you’re morbidly curious), but I became a much better programmer for it. Having had so much fun, I resolved to come back next year truly prepared.\nWhen December 2021 came, I threw myself into the puzzles. (I probably should have spent more time studying for exams instead, but this questionable time allocation thankfully didn’t hurt my GPA). The first few days came easily, aside from day 3, for which I kludged together an overcomplicated solution involving bitshifting. I switched between R and Python, preferring R for problems involving matrices and similar structures and Python where iteration was emphasized. Once again, I learned plenty along the way: queues for day 6, optimization for day 7, complex numbers as coordinates for day 11. For longer than I expected, I managed not to fall a day behind.\nBut that couldn’t last. I got badly stuck on part 2 of day 14 (which was not a hard problem, in hindsight). The end came on day 15, a tough problem involving graph traversal. I stalled out after hours of work, until a post on the subreddit pointed me toward Dijkstra’s algorithm. After writing probably the worst implementation of all time and letting my computer chug along for about an hour, I claimed both gold stars. But I had almost burnt myself out. The remaining puzzles (aside from a few easier “breather” problems) seemed impossible, and I ceased trying to keep up. Determined to keep going, I gutted my way through day 16, completing it only after spending hours looking in the wrong places for a simple bug. I knew then I had to stop.\nI had done better than I had expected; 50 stars seemed within reach. After taking a few days off, I knocked out a few of the easier puzzles, leaving thirty-odd stars secured. But then the spring semester started, depriving me of free time. Somehow, I still managed to complete the very challenging day 24, guided by a kind user on the Python discord. After that, as the holidays became a distant memory, Advent of Code fell to the bottom of my priorities.\nThat is, until I graduated. Without a job, and itching to work on something that didn’t involve complex data manipulation, I picked up where I had left off. The first puzzles fell with surprising ease: day 18, after some crude but effective string processing; day 19, after browsing the subreddit for tips; and even part 2 of day 21, completed after I spent half an hour fiddling with code I hadn’t touched for five months (when does that ever happen?). Day 22 stumped me for a while, so I asked for advice on the subreddit and followed a set-theory approach that ended up yielding a very elegant solution. That left just day 23: finding the optimal strategy for a simple puzzle that would be very, very hard to solve programatically. I dimly remembered some post on the subreddit recommending the A* algorithm. Knowing it was always smart to work out the problem with pen and paper before writing any code, I sketched out a game board, cut up some sticky notes to use as tokens, and set to work. I solved part 1 easily enough this way, so for the hell of it I tried again on part 2, which posed the same problem on an expanded game board. A few failed attempts later, I nearly gave up; I had learned the hard way how easily “just one more try” turns into a few hours of futile coding. But that time, I didn’t. When I entered my answer, I saw for the last time the familiar message:\nYou have solved part 2 of this puzzle! It provides one gold star.\nIt came as an anticlimax; I would not have to code that A* nightmare after all. Perversely, I felt cheated. Maybe I had cheated. The official description of Advent of Code entreats you to solve puzzles in “any programming language you like,” after all. Was I violating the spirit of the event by avoiding a programmatic solution entirely? Perhaps. The thought nags at me, so I suspect I’ll come back to this problem eventually, when I’m more confident in graph traversal algorithms. But still, I had all 50 stars, a feat that had seemed impossible just a year before.\nViewed one way, this is a trivial achievement: writing throwaway code to solve toy problems invented to kill time over in the weeks before Christmas. Viewed another way, it’s legitimately impressive. I solved all 25 of these puzzles in the time I could spare, just to sharpen my skills and indulge my love of the art of programming. I think it’s enough to say that grad students my age have found worse diversions. Either way, I emphasize that I had plenty of help: people on the subreddit and other forums to guide me, tutorials to consult, and above all the knowledge that many other people persevered through the same frustrations and got to 50 stars.\nI’ll probably be back next year, of course. I’ll have a lot less time to devote, since I expect to have a job by then. I don’t know if I’ll grind out all 50 stars again, now that I’ve done it already. But I do know that any time I spend on Advent of Code won’t be wasted, and I’ll be a better programmer for it.\nI just hope there aren’t as many graphs this time.\nMy repository for Advent of Code 2021: https://github.com/ryan-heslin/AoC2021"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Hello, world!",
    "section": "",
    "text": "Those goals are:\n\nEngage with the wider R community.\nShare some of the R esoterica I’ve learned\nLearn a web framework, as a first step toward more sophisticated web design\nPractice writing, which I find satisfies me the same way coding does\n\nI plan to mostly write about R and other data science topics, though I might broaden scope later on. If you’ve found your way here, I hope at least you’re entertained for a little while."
  },
  {
    "objectID": "posts/a_star/index.html",
    "href": "posts/a_star/index.html",
    "title": "Chasing A*: Completing Advent of Code 2021, Once and For All",
    "section": "",
    "text": "In an earlier post, I related my long but successful effort to obtain every last star in Advent of Code’s 2021 edition. It ended in surprising anticlimax when I solved day 23, a puzzle that looked daunting to tackle with code, using paper, pen, and some cut-up sticky notes. I could have stopped there. I should have stopped there. But good stories don’t end with an anticlimax, and the feeling that I had somehow cheated nagged at me. With plenty of free time as I hunted for a job, I decided to solve the puzzle the right way.\n\nThe Problem\nDay 23’s puzzle is a variant of the classic Towers of Hanoi. Instead of disks, the puzzle has players move different types of amphipod, in keeping with the year’s ocean theme. More importantly, the goal is to move each amphipod of each type into the correct “side room” connected to the main board, or “hall”, as efficiently as possible. The second part of the puzzle doubles the number of amphipods, making it much tougher to solve by hand.\nA post on the subreddit suggested using the A* (“A star”) algorithm. A*https://en.wikipedia.org/wiki/A*_search_algorithm) is a classic pathfinding algorithm that finds the shortest path between two given nodes of a graph. Implementations use a function called d to measure distances between nodes, and a heuristic function called h to estimate the distance between a node and the goal. The algorithm is mathematically certain to return the correct path if h never overestimates the distance to the goal.\nIn the problem at hand, the nodes were clearly game states (legal configurations of the board). Two nodes shared a connection if one could be reached from the other by a legal move (luckily, no legal moves are reversible, so the graph is acyclic — no loops are possible). The puzzle required the only the minimal cost of completing the game, not the actual sequence of moves, which further simplified things.\nStill, I faced several hard tasks:\n\nCreate a data structure capable of representing any valid game state\nImplement d (to measure distances between nodes) and h (to conservatively estimate any node’s distance from the goal).\nWrite an A_star function that used these routines to find the minimal cost\n\n\n\nInto the Fray\nAs is usual with Advent of Code, the first task was parsing the input. This was my raw input:\n#############\n#...........#\n###A#D#A#B###\n  #B#C#D#C#\n  #########\nI made the crucial decision to represent positions on the board as tuples of (x, y) coordinates. Since I was using Python, I decided to use a zero-based index, with the leftmost hall space as the x origin and the bottom side room spaces as the y origin. So the leftmost A amphipod on the board above would be located at (2, 2). I would have made my life much easier if I had used complex numbers instead of tuples of real numbers. In any case, I wrote a crude function to map each amphipod type to a set containing its positions:\ndef parse(inp, xmax=10):\n    stripped = inp[2 : (len(inp) - 1)]\n    ymax = len(stripped)\n    stripped.reverse()\n    stripped = list(zip(*stripped))\n    stripped = stripped[1 : (xmax + 1)]\n    mapping = {i: set() for i in range(4)}\n    for i in range(min(ends) + 2, max(ends) - 1, 2):\n        this = stripped[i]\n        for j in range(ymax):\n            val = values_map[this[j]]\n            mapping[val].add((i, j))  # Add position to set\n\n    return mapping, ymax\nThen I wrote a complicated function I’ll spare you. It computed, for each pair of coordinates it was legal to move between, the spaces spanning them. That way, I could allow moves only after confirming that that space wasn’t blocked.\nNext came designing an object to represent game states. It should own h and d, the second of which would take another game state as argument. I decided it should also be responsible for finding adjacent nodes and creating objects to represent them. I decided to call the class State.\nFrom here, my work only got kludgier. State ended up mapping each amphipod type to a set of the positions it occupied as well as tracking the occupants of each side room - a redundancy I couldn’t seem to avoid. From there, d and h were surprisingly simple. d would only ever be called on states that differed by the position of just one amphipod, so all I had to do was find the two coordinate tuples that disagreed in the instances’ coordinate sets, measure the distance between them, and multiply by the cost of moving the relevant amphipod type one space. h was a bit trickier, but hardly brutal — I just computed the distance from each amphipod to the target side room, a simple approach that would never underestimate the true cost.\nThe real bear turned out to be finding the valid neighbors of each instance. It took me an embarrassingly long time to figure out the rules:\n\nAmphipods in side rooms may only move out if they are in the side room of the wrong type, or if an amphipod of the wrong type is positioned behind them.\nAmphipods in side rooms that meet one or both criteria can move to any hall space to which the path is clear, or the innermost open space of their side room if it complies with rule 4.\nAmphipods in hall rooms may only move into the side room of their type, and only if a path to it is clear.\nA side room may only admit amphipods if it either contains no amphipods or only amphipods of its type.\n\nTranslating these directives into conditions was pure hell, and the result turned into pure write-only code. Here’s a representative excerpt:\nif coord[0] in self.sides_idx:\n    x_type = self.side_idx2type(coord[0])\n    if (x_type == k and self.sides[k][\"completed\"]) or (\n            coord[1] < self.ymax - 1\n            and self.sides[x_type][\"room\"][coord[1] + 1] is not None\n            ):\n        continue\nSomehow, I finished it.\nThat left only the A_star function that did the real work. Translating Wikipedia’s pseudocode for the algorithm into Python was simple:\ndef A_star(start, goal, debug=False):\n    start_k = hash(start)\n    open_set = {start_k: start}\n\n    # For node k, node preceding it on cheapest known path to k\n    came_from = {}\n\n    # g_score[k] is cost of cheapest known path to k\n    g_score = defaultdict(lambda: inf)\n    g_score[start_k] = 0\n    # gscore[k] + k.h() - best estimate of total cost (default to infinity if node unknown)\n    f_score = defaultdict(lambda: inf)\n    f_score[start_k] = g_score[start_k] + start.h()\n\n    while open_set:\n        min_cost = inf\n        # h = hash\n        for h, node in open_set.items():\n            score = f_score[h]\n            this_cost = min(min_cost, score)\n            if this_cost < min_cost and h in open_set.keys():\n                current = node\n                # print(current)\n                # print(\"\\n\")\n                if current == goal:\n                    return g_score[hash(current)]  # Cheapest cost to goal\n                min_cost = this_cost\n        current_k = hash(current)\n        current.find_neighbors()\n        if debug:\n            print(hash(current))\n            print(current)\n            print(\"-------------------\\n\")\n            for n in current.neighbors:\n                print(n)\n                print(current.d(n))\n            input(\"Continue: \")\n            print(\"\\n\\n\\n\")\n        open_set.pop(current_k)\n        for neighbor in current.neighbors:\n            # print(neighbor.neighbors)\n\n            # Distance from start to neighbor through current\n            g_score_new = g_score[current_k] + current.d(neighbor)\n            # print(f\"distance: {current.d(neighbor)}\")\n            # print(neighbor)\n            neighbor_k = hash(neighbor)\n            # This path to neighbor cheaper than any known, so record it\n            if g_score_new < g_score[neighbor_k]:\n                came_from[neighbor_k] = current\n                # New estimate of cost from this neighbor\n                # Forgot this line\n                g_score[neighbor_k] = g_score_new\n                f_score[neighbor_k] = g_score_new + neighbor.h()\n                if neighbor not in open_set.values():\n                    open_set[neighbor_k] = neighbo\nMy only addition, naturally, was a debug mode. Then came the really hard part.\nI spent an embarrassing amount of time in the debugger getting everything to work correctly. I fell into in a dispiriting loop of scanning output for evidence of bugs, stepping through the debugger to track them down, and making painstaking changes to fix them. I came close to giving up, and several times regretted starting. Then, one fine July Monday morning, I saw the code spit out a plausible-looking answer. Not expecting success, I checked the Advent of Code website and gasped when I saw it was correct.\nI wasn’t home free; my inefficient kludge algorithm might well be too slow for the second half of the problem. I modified State to handle a larger game board, crossed my fingers, and ran the script again. It took a few minutes longer, but it spit out the correct answer for part 2. I had done it.\nI savored the feeling of blissful triumph, knowing it would not last. I might have just finished the worst implementation of A* of all time, but it was my implementation, and it solved the problem. Somehow, writing your own intricate kludge is far more satisfying then copying someone else’s elegant solution. In any case, I was at last done: I had finished all 25 puzzles for Advent of Code 2021 by myself. Perhaps an achievement in pointlessness, but an achievement nonetheless."
  }
]