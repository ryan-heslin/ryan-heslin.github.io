<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8" />
<meta name="generator" content="quarto-1.3.450" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />

<meta name="author" content="Ryan Heslin" />
<meta name="dcterms.date" content="2023-09-11" />

<title>Verso – Why Linear Algebra is Useful</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<!-- htmldependencies:E3FAD763 -->
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": true,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

<link href="../../site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="../../site_libs/pagedtable-1.1/js/pagedtable.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>


<link rel="stylesheet" href="../../styles.css" />
</head>

<body>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="/index.html">
    <span class="navbar-title">Verso</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse"
  aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation"
  onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="/about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ryan-heslin" rel="" target=""><i 
  class="bi bi-github" 
  role="img" 
>
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.linkedin.com/in/ryan-heslin/" rel="" target="">
 <span class="menu-text">LinkedIn</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="/index.html" rel="" target="">
 <span class="menu-text">RSS</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <div id="quarto-toc-target"></div>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
  <div class="quarto-title-banner">
    <div class="quarto-title column-body">
      <h1 class="title">Why Linear Algebra is Useful</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Miscellaneous</div>
                <div class="quarto-category">Math</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Ryan Heslin </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">September 11, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header>

<p>Linear algebra has a bad reputation. The subject has a tough combination of fiddly computation and abstract reasoning, one that isn’t always taught well. STEM majors often have bitter memories of spending hours on <a href="https://en.wikipedia.org/wiki/Gaussian_elimination">row reduction</a> and <a href="https://en.wikipedia.org/wiki/QR_decomposition">QR decomposition</a>. But sometimes linear algebra can make your life much, much easier. One such situation is expressing the formula for computing linear regression coefficients.</p>
<section id="what-does-linear-regression-actually-do" class="level1">
<h1>What does Linear Regression Actually Do?</h1>
<p>Formally, <a href="https://en.wikipedia.org/wiki/Ordinary_least_squares">ordinary least squares</a> regression takes a data matrix <span class="math inline">\(X\)</span> and a response vector <span class="math inline">\(Y\)</span>, and finds a vector of coefficients <span class="math inline">\(\beta\)</span> that minimize the equation <span class="math inline">\(\sum_{i=1}^n (Y_i - \hat Y)^2\)</span>, where <span class="math inline">\(\hat Y = X \beta\)</span>. This is called the sum of squared errors (<span class="math inline">\(SSE\)</span>). It can also be viewed as the sum of the squares of the Euclidean distance between each response value <span class="math inline">\(Y_i\)</span> and the corresponding fitted value <span class="math inline">\(\hat Y_i\)</span>. (Why squared distance instead of absolute value? See below). The individual errors are called residuals.</p>
<p>Simple linear regression is the special case where there is only one variable, <span class="math inline">\(X_1\)</span>, and hence two coefficients: the constant term <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, the coefficient for <span class="math inline">\(X_1\)</span>. (<span class="math inline">\(\beta_0\)</span> isn’t strictly necessary, but it’s rarely a good idea to omit it). In simple regression, <span class="math inline">\(\hat Y_i = \beta_0 + \beta_1 X_{i1}\)</span></p>
<p>This is equivalent to plotting the data and finding the line that minimizes the sum of squared errors. <span class="math inline">\(\beta_0\)</span> provides the intercept of the line.</p>
<p>Here is a model with the residuals shown:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="sourceCode r source cell-code"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">10</span>, <span class="dv">5</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> X <span class="sc">*</span> <span class="dv">7</span> <span class="sc">+</span> <span class="dv">4</span> <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">20</span>, <span class="dv">4</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y)) <span class="sc">+</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">linewidth =</span> <span class="fl">0.7</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> .<span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x =</span> X, <span class="at">y =</span> model<span class="sc">$</span>fitted.values, <span class="at">xend =</span> X, <span class="at">yend =</span> Y), <span class="at">color =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>-- `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="index_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672" /></p>
</figure>
</div>
</div>
</div>
<p>Now we have to know how to find these coefficients <span class="math inline">\(\beta\)</span>. There the trouble starts.</p>
</section>
<section id="elementary-algebra" class="level1">
<h1>Elementary Algebra</h1>
<p>Statistics textbooks usually introduce the equations for the estimators in simple linear regression using these formulae (or algebraically equivalent expressions): <span class="math display">\[
\displaylines{\beta_0 = \bar Y -\beta_1 \bar X \\
\beta_1 = \frac{\sum_{i=1}^n(X_i - \bar X)(Y_i - \bar Y)}{\sum_{i = 1}^n (X_i - \bar X)^2}}
\]</span></p>
<p>Professors often throw these complicated formulae at unsuspecting students in the last weeks of intro stats courses. I first encountered them that way, and I remember the shock of fear I felt. Nobody with mathematical maturity is scared of a summation symbol, but back then I had no clue what I was doing, and many other students are in the same position.</p>
<p>There’s also the classic assignment of <em>deriving</em> these formulae by minimizing the normal equation <span class="math inline">\(SSE = \sum_{i=1}^n(y_i - \beta_0 - \beta_1 x_i)^2\)</span>. You have to take first derivatives, solve the equations for each estimator simultaneously, do some algebra tricks, and finish off with a second-derivative test to make sure the estimators really do minimize the loss function. It’s one of those tough but brutally satisfying assignments, like computing a median with standard SQL or implementing iterative least squares to estimate a generalized linear model. (I appreciate the professor who suggested doing it as an exercise; it made me a lot less mathematically naive!).</p>
</section>
<section id="linear-algebra" class="level1">
<h1>Linear Algebra</h1>
<p>In linear algebra terms, linear regression <a href="https://textbooks.math.gatech.edu/ila/projections.html">orthogonally projects</a> the response vector <span class="math inline">\(Y\)</span> into the linear subspace formed by the data matrix <span class="math inline">\(X\)</span>. (Linear algebra texts usually call a generic matrix <span class="math inline">\(A\)</span>, but statistics texts use <span class="math inline">\(X\)</span> for a data matrix, so I will do so here). In other words, it finds the closest vector to <span class="math inline">\(Y\)</span> by Euclidean distance that can be formed by a <a href="https://en.wikipedia.org/wiki/Linear_combination">linear combination</a> of <span class="math inline">\(X\)</span>. In matrix algebra, the normal equation is <span class="math inline">\(SSE = (Y-\beta X)^T(Y- \beta_ X)\)</span>. (Multiplying a row vector by its transpose just sums the squares of each element). Some basic calculus and rearrangement turns this into <span class="math inline">\(X^TX \beta = X^Ty\)</span>. By inverting <span class="math inline">\(X^TX\)</span> (a matrix operation roughly analogous to turning a number <span class="math inline">\(n\)</span> into <span class="math inline">\(1/n\)</span>), we get a simple formula for <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
\beta = (X^TX)^{-1}X^Ty
\]</span></p>
<p>This is a variation on the formula for a projection matrix, <span class="math inline">\(P = X(X^TX)^{-1}X^T\)</span>. For any vector <span class="math inline">\(y\)</span>, <span class="math inline">\(Py\)</span> is the closest vector to <span class="math inline">\(y\)</span> by Euclidean distance that is a linear combination of the vectors in <span class="math inline">\(X\)</span>. This is much more revealing than the elementary-algebra version of the formula. For one thing, it’s a lot simpler. It’s fully general, too: it holds for all coefficients for a data matrix of any size, not just simple linear regression. (What about <span class="math inline">\(\beta_0\)</span>, the constant term? Just add a column of ones to your data matrix, and you have it!). And it implies the important fact that no unique least-squares solution exists if <span class="math inline">\((X^TX)\)</span> fails to be invertible, which happens if the <a href="https://en.wikipedia.org/wiki/Rank_(linear_algebra)">rank</a> of <span class="math inline">\(X\)</span> is less than <span class="math inline">\(p\)</span>, the number of variables. In that case, there are infinitely many least-squares solutions.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>As this example shows, matrix notation is more abstract and concise than scalar notation. It makes the underlying concepts of an expression like this far easier to see and understand. It’s the difference between implementing a function in Python and implementing it in C, except without the loss in efficiency.</p>
<p>This is just one example of how linear algebra makes it easy to express ideas that would be hard to convey with elementary algebra. Those weeks of row-reducing matrices really were worth it.</p>
<div id="quarto-navigation-envelope" class="hidden">
<p><span class="hidden" data-render-id="quarto-int-sidebar-title">Verso</span> <span class="hidden" data-render-id="quarto-int-navbar-title">Verso</span> <span class="hidden" data-render-id="quarto-int-navbar:About">About</span> <span class="hidden" data-render-id="quarto-int-navbar:/about.html">/about.html</span> <span class="hidden" data-render-id="quarto-int-navbar:https://github.com/ryan-heslin">https://github.com/ryan-heslin</span> <span class="hidden" data-render-id="quarto-int-navbar:LinkedIn">LinkedIn</span> <span class="hidden" data-render-id="quarto-int-navbar:https://www.linkedin.com/in/ryan-heslin/">https://www.linkedin.com/in/ryan-heslin/</span> <span class="hidden" data-render-id="quarto-int-navbar:RSS">RSS</span> <span class="hidden" data-render-id="quarto-int-navbar:/index.html">/index.html</span></p>
</div>
<div id="quarto-meta-markdown" class="hidden">
<p><span class="hidden" data-render-id="quarto-metatitle">Verso - Why Linear Algebra is Useful</span> <span class="hidden" data-render-id="quarto-twittercardtitle">Verso - Why Linear Algebra is Useful</span> <span class="hidden" data-render-id="quarto-ogcardtitle">Verso - Why Linear Algebra is Useful</span> <span class="hidden" data-render-id="quarto-metasitename">Verso</span> <span class="hidden" data-render-id="quarto-twittercarddesc"></span> <span class="hidden" data-render-id="quarto-ogcardddesc"></span></p>
</div>
<!-- -->
<div class="quarto-embedded-source-code">
<div class="sourceCode" id="cb3" data-shortcodes="false"><pre class="sourceCode markdown"><code class="sourceCode markdown"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> &quot;Why Linear Algebra is Useful&quot;</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> &quot;Ryan Heslin&quot;</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> &quot;2023-09-11&quot;</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [&quot;Miscellaneous&quot;, &quot;Math&quot;]</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="an">urlcolor:</span><span class="co"> &quot;blue&quot;</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>Linear algebra has a bad reputation. The subject has a tough </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>combination of fiddly computation and abstract reasoning,</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>one that isn&#39;t always taught well.</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>STEM majors often have bitter memories </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>of spending hours on <span class="co">[</span><span class="ot">row reduction</span><span class="co">](https://en.wikipedia.org/wiki/Gaussian_elimination)</span> and <span class="co">[</span><span class="ot">QR decomposition</span><span class="co">](https://en.wikipedia.org/wiki/QR_decomposition)</span>. </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>But sometimes linear algebra can make your life much, much easier. One such </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>situation is expressing the formula for computing linear regression coefficients.</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="fu"># What does Linear Regression Actually Do? </span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>Formally, <span class="co">[</span><span class="ot">ordinary least squares</span><span class="co">](https://en.wikipedia.org/wiki/Ordinary_least_squares)</span> </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>regression takes a data matrix $X$ and a response vector $Y$, and </span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>finds a vector of coefficients $\beta$ that minimize the equation $\sum_{i=1}^n (Y_i - \hat Y)^2$, </span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>where $\hat Y = X \beta$. This is called the sum of squared errors ($SSE$). It can also be viewed as the sum of the squares of </span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>the Euclidean distance between each response value $Y_i$ and the corresponding fitted value $\hat Y_i$. </span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>(Why squared distance instead of absolute value? See below). The individual errors are called residuals.</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>Simple linear regression is the special case where there is </span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>only one variable, $X_1$, and hence two coefficients: the constant term $\beta_0$ and </span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>$\beta_1$, the coefficient for $X_1$. ($\beta_0$ isn&#39;t strictly necessary, but it&#39;s rarely </span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>a good idea to omit it). In simple regression, $\hat Y_i = \beta_0 + \beta_1 X_{i1}$ </span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>This is equivalent to plotting the data and finding the line that minimizes the sum of </span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>squared errors. $\beta_0$ provides the intercept of the line.</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>Here is a model with the residuals shown:</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>quarto-executable-code-5450563D</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a><span class="in">```r</span></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">10</span>, <span class="dv">5</span>)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> X <span class="sc">*</span> <span class="dv">7</span> <span class="sc">+</span> <span class="dv">4</span> <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">20</span>, <span class="dv">4</span>) </span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X)</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y)) <span class="sc">+</span> </span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">linewidth =</span> <span class="fl">0.7</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">alpha =</span> .<span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x =</span> X, <span class="at">y =</span> model<span class="sc">$</span>fitted.values, <span class="at">xend =</span> X, <span class="at">yend =</span> Y), <span class="at">color =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>()</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>Now we have to know how to find these coefficients $\beta$. There the trouble starts.</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a><span class="fu"># Elementary Algebra</span></span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>Statistics textbooks usually introduce the equations for the estimators </span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>in simple linear regression using these formulae (or algebraically equivalent expressions):</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>\displaylines{\beta_0 = \bar Y -\beta_1 \bar X <span class="sc">\\</span></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>\beta_1 = \frac{\sum_{i=1}^n(X_i - \bar X)(Y_i - \bar Y)}{\sum_{i = 1}^n (X_i - \bar X)^2}}</span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a>Professors often throw these complicated formulae at unsuspecting students </span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a>in the last weeks of intro stats courses. I first encountered them that way, and I remember the shock of fear I felt. Nobody with mathematical maturity is scared of a </span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>summation symbol, but back then I had no clue what I was doing, and many </span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a>other students are in the same position.</span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a>There&#39;s also the classic assignment of _deriving_ these formulae by minimizing the </span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a>normal equation $SSE = \sum_{i=1}^n(y_i - \beta_0 - \beta_1 x_i)^2$. You have to take first derivatives, solve the equations for each estimator simultaneously, </span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>do some algebra tricks, and finish off with a second-derivative test to make sure </span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a>the estimators really do minimize the loss function. It&#39;s one of those tough </span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>but brutally satisfying assignments, like computing a median with standard SQL </span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a>or implementing iterative least squares to estimate a generalized linear model.</span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a>(I appreciate the professor who suggested doing it as an exercise; it made me </span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a>a lot less mathematically naive!).</span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a><span class="fu"># Linear Algebra</span></span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a>In linear algebra terms, linear regression <span class="co">[</span><span class="ot">orthogonally projects</span><span class="co">](https://textbooks.math.gatech.edu/ila/projections.html)</span> the response vector $Y$ into the linear subspace formed by the data matrix $X$.</span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a>(Linear algebra texts usually call a generic matrix $A$, but statistics </span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a>texts use $X$ for a data matrix, so I will do so here).</span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true" tabindex="-1"></a> In other words, it finds the closest </span>
<span id="cb3-84"><a href="#cb3-84" aria-hidden="true" tabindex="-1"></a>vector to $Y$ by Euclidean distance that can be formed by a <span class="co">[</span><span class="ot">linear combination</span><span class="co">](https://en.wikipedia.org/wiki/Linear_combination)</span> of $X$. </span>
<span id="cb3-85"><a href="#cb3-85" aria-hidden="true" tabindex="-1"></a>In matrix algebra, the normal equation is $SSE = (Y-\beta X)^T(Y- \beta_ X)$. </span>
<span id="cb3-86"><a href="#cb3-86" aria-hidden="true" tabindex="-1"></a>(Multiplying a row vector by its transpose just sums the squares of each element).</span>
<span id="cb3-87"><a href="#cb3-87" aria-hidden="true" tabindex="-1"></a>Some basic calculus and rearrangement turns this into $X^TX \beta = X^Ty$.</span>
<span id="cb3-88"><a href="#cb3-88" aria-hidden="true" tabindex="-1"></a>By inverting $X^TX$ (a matrix operation roughly analogous to turning a number $n$ into $1/n$), we get a simple formula for $\beta$: </span>
<span id="cb3-89"><a href="#cb3-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-90"><a href="#cb3-90" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb3-91"><a href="#cb3-91" aria-hidden="true" tabindex="-1"></a>\beta = (X^TX)^{-1}X^Ty</span>
<span id="cb3-92"><a href="#cb3-92" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-93"><a href="#cb3-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-94"><a href="#cb3-94" aria-hidden="true" tabindex="-1"></a>This is a variation on the formula for a projection matrix, $P = X(X^TX)^{-1}X^T$. </span>
<span id="cb3-95"><a href="#cb3-95" aria-hidden="true" tabindex="-1"></a>For any vector $y$, $Py$ is the closest vector to $y$ by Euclidean distance that is a </span>
<span id="cb3-96"><a href="#cb3-96" aria-hidden="true" tabindex="-1"></a>linear combination of the vectors in $X$.</span>
<span id="cb3-97"><a href="#cb3-97" aria-hidden="true" tabindex="-1"></a>This is much more revealing than the elementary-algebra version of the </span>
<span id="cb3-98"><a href="#cb3-98" aria-hidden="true" tabindex="-1"></a>formula. For one thing, it&#39;s a lot simpler. It&#39;s fully general, too: it holds for all coefficients</span>
<span id="cb3-99"><a href="#cb3-99" aria-hidden="true" tabindex="-1"></a>for a data matrix of any size, not just simple linear regression. (What about </span>
<span id="cb3-100"><a href="#cb3-100" aria-hidden="true" tabindex="-1"></a>$\beta_0$, the constant term? Just add a column of ones to your data matrix, and you have it!).</span>
<span id="cb3-101"><a href="#cb3-101" aria-hidden="true" tabindex="-1"></a>And it implies the important fact that no unique least-squares solution exists </span>
<span id="cb3-102"><a href="#cb3-102" aria-hidden="true" tabindex="-1"></a>if $(X^TX)$ fails to be invertible, which happens if the <span class="co">[</span><span class="ot">rank</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Rank_(linear_algebra)) of $X$ is less </span>
<span id="cb3-103"><a href="#cb3-103" aria-hidden="true" tabindex="-1"></a>than $p$, the number of variables. In that case, there are infinitely many </span>
<span id="cb3-104"><a href="#cb3-104" aria-hidden="true" tabindex="-1"></a>least-squares solutions.</span>
<span id="cb3-105"><a href="#cb3-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-106"><a href="#cb3-106" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusion</span></span>
<span id="cb3-107"><a href="#cb3-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-108"><a href="#cb3-108" aria-hidden="true" tabindex="-1"></a>As this example shows, matrix notation is more abstract and concise than scalar notation. It makes </span>
<span id="cb3-109"><a href="#cb3-109" aria-hidden="true" tabindex="-1"></a>the underlying concepts of an expression like this far easier to see and understand. </span>
<span id="cb3-110"><a href="#cb3-110" aria-hidden="true" tabindex="-1"></a>It&#39;s the difference between implementing a function in Python and implementing it in C, except without the loss in efficiency.</span>
<span id="cb3-111"><a href="#cb3-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-112"><a href="#cb3-112" aria-hidden="true" tabindex="-1"></a>This is just one example of how linear algebra makes it easy to express </span>
<span id="cb3-113"><a href="#cb3-113" aria-hidden="true" tabindex="-1"></a>ideas that would be hard to convey with elementary algebra.</span>
<span id="cb3-114"><a href="#cb3-114" aria-hidden="true" tabindex="-1"></a>Those weeks of row-reducing matrices really were worth it.</span></code></pre></div>
</div>
</section>

</main> <!-- /main -->
<script id = "quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->

</body>

</html>